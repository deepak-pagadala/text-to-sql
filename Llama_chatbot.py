import os
import re
import sqlite3
import faiss 
import torch
import numpy as np
import pandas as pd
import streamlit as st
from sentence_transformers import SentenceTransformer
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch
from dotenv import load_dotenv

load_dotenv()

HF_TOKEN = os.getenv("HF_TOKEN")
if not HF_TOKEN:
    raise RuntimeError("HF_TOKEN not set in .env")

# paths
db_path = 'chatbot22.db'
ntee_path = 'NTEE_descriptions.csv'
samplequery_path = 'sample_query.csv'  

LLAMA_MODEL_ID = "meta-llama/Llama-2-7b-chat-hf"


device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(
    LLAMA_MODEL_ID,
    token=HF_TOKEN,
)
llama_model = AutoModelForCausalLM.from_pretrained(
    LLAMA_MODEL_ID,
    device_map="auto",         # let accelerate shard it
    torch_dtype=torch.float16,
    token=HF_TOKEN,
)

def llama_generate(prompt: str) -> str:
    wrapped = f"<s>[INST] {prompt} [/INST]</s>"
    inputs = tokenizer(wrapped, return_tensors="pt").to(device)
    outputs = llama_model.generate(**inputs, max_new_tokens=256)
    text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return text.split("[/INST]")[-1].strip()

with sqlite3.connect(db_path) as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = cursor.fetchall()

# Columns renaming
COLUMN_MAPPING = {
    "research_org_pseudonym": "foundation_giver_id",
    "org_name": "organization_name",
    "org_city": "organization_city",
    "org_state": "organization_state",
    "org_zip": "organization_zipcode",
    "org_county_code": "organization_county_code",
    "org_ntee_code": "organization_ntee_code",
    "org_classification_desc_short": "org_classification_desc_short",
    "org_classification_desc_medium": "org_classification_desc_medium",
    "org_num_employees": "number_of_employees_in_organization",
    "org_num_volunteers": "number_of_volunteers_in_organization",
    "org_total_expenses": "total_expenses_of_organization",
    "org_assets": "organization_assets",
    "org_liabilities": "organization_liabilities",
    "org_total_revenue": "total_revenue_of_organization",
    "org_type": "organization_type",
    "org_subtype": "organization_subtype",
    "org_date_established": "date_when_organization_was_established",
    "org_naics_code": "organization_naics_code",
    "org_address": "organization_address",
    "org_latitude": "organization_latitude",
    "org_longitude": "organization_longitude",
    "org_financial_year_start": "financial_start_year_of_organization",
    "org_financial_year_end": "financial_end_year_of_organization",
    "org_revenue_contributions": "organization_revenue_contributions",
    "org_mission_statement_summary": "organization_mission_statement_summary",
    "org_source": "organization_source",
    "org_government_revenue": "organization_government_revenue",
    "org_ntee_major10": "organization_nteecode_first_letter",
    "org_county_name": "organization_county_name",
    "org_rurality_percentage": "organization_rurality_percentage",
    "org_county_class": "organization_county_class",
    "giver_id" : "foundation_giver_id",
    "grant_date" : "grant_date",
    "grant_amount" : "grant_amount",
    "g_city" : "grantee_city",
    "g_state" : "grantee_state",
    "g_zip" : "grantee_zipcode",
    "g_ein" : "grantee_ein",
    "g_name" : "grantee_name",
    "f_city" : "foundation_city",
    "f_state" : "foundation_state",
    "f_zip" : "foundation_zipcode",
    "f_state_name" : "foundation_state_name",
    "f_region_4" : "foundation_region_4",
    "f_region_9" : "foundation_region_9",
    "g_state_name" : "grantee_state_name",
    "g_region_4" : "grantee_region_4",
    "g_region_9" : "grantee_region_9",
    "f_ein" : "foundation_ein",
    "f_name" : "foundation_name",
    "grant_source" : "grant_source",
    "formation_yr" : "formation_year",
    "ruling_yr" : "ruling_year",
    "f_mission_partI" : "foundation_mission_partI",
    "f_mission_partIII" : "foundation_mission_partIII",
    "g_mission_partI" : "grantee_mission_partI",
    "g_mission_partIII" : "grantee_mission_partIII",
    "f_ntee_letter" : "foundation_ntee_code",
    "g_ntee_letter" : "grantee_ntee_code",
    "f_ntee_description" : "foundation_ntee_description",
    "g_ntee_description" : "grantee_ntee_description",
    "f_ntee_major8" : "foundation_ntee_short_description",
    "f_ntee_major10" : "foundation_ntee_description_abbreviation",
    "f_ntee_major12" : "foundation_ntee_major12",
    "g_ntee_major8" : "grantee_ntee_short_description",
    "g_ntee_major10" : "grantee_ntee_description_abbreviation",
    "g_ntee_major12" : "grantee_ntee_major12",
    "f_amt_assets_total" : "foundation_assets_total",
    "f_amt_exp_grants" : "foundation_amount_exp_grants",
    "f_num_employees" : "foundation_number_of_employees",
    "f_num_volunteers" : "foundation_number_of_volunteers",
    "g_amt_assets_total" : "grantee_assets_total",
    "g_amt_exp_total" : "grantee_amount_exp_total",
    "g_num_employees" : "grantee_number_of_employees",
    "g_num_volunteers" : "grantee_number_of_volunteers",
    "g_amt_rev_contrib_total" : "grantee_revenue_contribution_total",
    "g_amt_rev_total" : "grantee_revenue_total"
}

RESTRICTED_COLUMNS = [
    'grantee_ntee_description',
    'foundation_ntee_description',
    'grantee_ntee_major12',
    'grantee_ntee_description_abbreviation',
    'foundation_ntee_major12',
    'foundation_ntee_description_abbreviation',
    'foundation_ntee_short_description',
    'grantee_ntee_short_description',
    'organization_nteecode_first_letter'
]


model = SentenceTransformer('all-MiniLM-L6-v2')

def get_ntee_code_from_csv(user_query, ntee_path):
    """
    Load the CSV file containing NTEE descriptions, perform semantic search over the descriptions,
    and return the best matching NTEE code along with its detailed description.
    """
    df_ntee = pd.read_csv(ntee_path, encoding='latin1')
    if "org_class_code" not in df_ntee.columns or "class_short_description" not in df_ntee.columns:
        raise ValueError("CSV file must contain 'org_class_code' and 'class_short_description' columns.")

    model_ntee = SentenceTransformer('all-MiniLM-L6-v2')
    descriptions = df_ntee["class_short_description"].tolist()
    desc_embeddings = model_ntee.encode(descriptions)
    user_embedding = model_ntee.encode([user_query])

    norm_desc = desc_embeddings / np.linalg.norm(desc_embeddings, axis=1, keepdims=True)
    norm_query = user_embedding / np.linalg.norm(user_embedding)
    cosine_similarities = np.dot(norm_desc, norm_query.T).squeeze()

    best_idx = int(np.argmax(cosine_similarities))
    best_ntee_code = df_ntee.iloc[best_idx]["org_class_code"]
    best_ntee_description = df_ntee.iloc[best_idx]["class_short_description"]

    return best_ntee_code, best_ntee_description


def is_organization_query(query):
    """
    Determines if a query is organization-related.
    Uses semantic similarity with a centroid approach.
    """

    org_examples = [
        "Which foundations have provided the highest grants?",
        "Tell me about the foundations giving grants.",
        "List organizations that offer grants.",
        "What organizations support environmental projects?"
    ]

    non_org_examples = [
        "What is the weather in New York?",
        "Show me the sales numbers for Q3.",
        "How many users signed up today?"
    ]

    return classify_query(query, org_examples, non_org_examples, model)

def is_grantee_query(query):
    """
    Determines if a query is grantee-related.
    """

    grantee_examples = [
        "Which grantees received the highest funding?",
        "Tell me about the grantees that got the most grants.",
        "List grantees who work in education.",
        "Which organizations have received the most grants?"
    ]

    non_grantee_examples = [
        "Which organizations gave the highest grants?",
        "Show foundations supporting healthcare.",
        "How many users signed up today?"
    ]

    return classify_query(query, grantee_examples, non_grantee_examples, model)

def is_sector_related_query(query):
    """
    Determines if the query is related to a sector or industry.
    """

    sector_examples = [
        "Which foundations support education?",
        "Give me organizations in the healthcare sector.",
        "List tech-focused grant providers."
    ]

    non_sector_examples = [
        "Which organizations gave the highest grants?",
        "How many companies donated over $10 million?",
        "List organizations by their total grants."
    ]

    return classify_query(query, sector_examples, non_sector_examples, model)

def classify_query(query, positive_examples, negative_examples, model):
    """
    General function for query classification using centroid-based similarity.
    """
    pos_embeddings = model.encode(positive_examples)
    neg_embeddings = model.encode(negative_examples)
    pos_centroid = np.mean(pos_embeddings, axis=0)
    neg_centroid = np.mean(neg_embeddings, axis=0)

    query_embedding = model.encode([query])[0]
    query_embedding_norm = query_embedding / np.linalg.norm(query_embedding)

    sim_pos = np.dot(query_embedding_norm, pos_centroid / np.linalg.norm(pos_centroid))
    sim_neg = np.dot(query_embedding_norm, neg_centroid / np.linalg.norm(neg_centroid))

    return sim_pos > sim_neg

def fetch_schema_from_db(db_path):
    """
    Extracts the database schema dynamically.
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = cursor.fetchall()
    schemas = {}
    for table in tables:
        table_name = table[0]
        cursor.execute(f'PRAGMA table_info("{table_name}");')
        #columns = [column[1] for column in cursor.fetchall()]
        columns = [COLUMN_MAPPING.get(column[1], column[1]) for column in cursor.fetchall()]
        schemas[table_name] = columns

    conn.close()
    return schemas

def create_faiss_index(schema_texts):
    """
    (Optional) Create a FAISS index based on schema text embeddings.
    (Our code: for potential similarity search over schema details)
    """
    #model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(schema_texts)
    embeddings = np.array(embeddings).astype('float32')
    faiss_index = faiss.IndexFlatL2(embeddings.shape[1])
    faiss_index.add(embeddings)
    faiss.write_index(faiss_index, "index_file.index")
    return faiss_index

def generate_multiple_sql_queries_with_schema(user_query, schemas):
    """
    Generate up to three SQL queries based on the user query, 
    including NTEE enrichment when relevant, using Llama-2.
    """
    # Build the schema description
    relevant_schema = "\n".join(
        f"Table: {table} - Columns: {', '.join(cols)}"
        for table, cols in schemas.items()
    )

    # Enrich with NTEE code if organization/grantee + sector
    if (is_organization_query(user_query) or is_grantee_query(user_query)) \
       and is_sector_related_query(user_query):
        detected_ntee_code, detected_description = get_ntee_code_from_csv(user_query, ntee_path)
        user_query = f"{user_query} (NTEE Code: {detected_ntee_code} - {detected_description})"

    # Few-shot examples for SQL style guidance
    few_shot_examples = """
    Example 1:
    Question: Which foundations have given the highest amount of grants?
    SQL Query: SELECT foundation_name, MAX(grant_amount) AS max_grant 
               FROM your_table 
               GROUP BY foundation_name 
               ORDER BY max_grant DESC;

    Example 2:
    Question: Show the top 5 grantees in the healthcare sector.
    SQL Query: SELECT grantee_name, SUM(grant_amount) AS total_grants 
               FROM your_table 
               WHERE sector LIKE '%health%' 
               GROUP BY grantee_name 
               ORDER BY total_grants DESC 
               LIMIT 5;
    """

    prompt = f"""
User Query: {user_query}

Few-shot Examples:
{few_shot_examples}

Schema Details:
{relevant_schema}

Generate the most relevant SQL query for the given prompt. Ensure that the query is syntactically correct and works with the provided schema.
If you have to compare something, use the LIKE operator. For state codes, use abbreviations.
Do NOT use the following columns in any query: {RESTRICTED_COLUMNS}.
Return ONLY the SQL query in a single line. Do not include any explanations.
""".strip()

    # Call Llama-2 via our wrapper
    llm_output = llama_generate(prompt)

    # Split into lines and return up to three queries
    sql_queries = [line.strip() for line in llm_output.splitlines() if line.strip()]
    return sql_queries[:3]


def execute_sql_query(db_path, sql_query):
    """
    Execute the given SQL query on the SQLite database and return the results.
    (Our code)
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    try:
        cursor.execute(sql_query)
        results = cursor.fetchall()
        return results
    except sqlite3.Error as e:
        return f"An error occurred: {e}"
    finally:
        conn.close()

def revert_aliases_in_query(sql_query):
    """
    Convert user-friendly column names back to their original names for execution.
    """
    reverse_mapping = {v: k for k, v in COLUMN_MAPPING.items()}
    for alias, original in reverse_mapping.items():
        sql_query = re.sub(rf"\b{alias}\b", original, sql_query)
    return sql_query

def clean_sql_query(query):
    """
    Clean the SQL query by removing unwanted markdown or formatting.
    (Our code)
    """
    query_cleaned = re.sub(r'`{3}sql|`', '', query).strip()
    return query_cleaned

def summarize_findings_with_llm(query, schema, results):
    """
    Generate a human-friendly summary of the SQL query results using Llama-2.
    """
    # Build schema description
    schema_text = "\n".join(
        f"Table: {table_name} - Columns: {', '.join(columns)}"
        for table_name, columns in schema.items()
    )
    # Format results
    result_text = "\n".join(str(record) for record in results)

    # Optionally pull sector info from the last column
    sector_info = ""
    if results and isinstance(results[0], (list, tuple)) and len(results[0]) >= 3:
        sector_desc = results[0][-1]
        if isinstance(sector_desc, str) and len(sector_desc) > 3:
            sector_info = f"This query is related to the sector: '{sector_desc}'.\n\n"

    # Build the prompt
    prompt = f"""
User Query: {query}

Schema Details:
{schema_text}

SQL Results:
{result_text}

{sector_info}
Generate a concise, human-friendly summary of the results in about 50 words. 
Be specific about the sector or topic.
""".strip()

    # Call Llama-2 via our wrapper
    summary = llama_generate(prompt)
    return summary



def run_pipeline(user_query, db_path):
    """
    Run the full pipeline: dynamically extract the schema, generate SQL queries, execute one that returns results,
    and summarize the findings.
    (Combined approach)
    """
    schemas = fetch_schema_from_db(db_path)
    generated_sql_queries = generate_multiple_sql_queries_with_schema(user_query, schemas)

    for query in generated_sql_queries:
        cleaned_query = clean_sql_query(query)
        sql_query_for_db = revert_aliases_in_query(cleaned_query)
        results = execute_sql_query(db_path, sql_query_for_db)

        if results and not isinstance(results, str):
            try:
                df_ntee = pd.read_csv(ntee_path, encoding='latin1')
                code_to_desc = dict(zip(df_ntee['org_class_code'], df_ntee['class_short_description']))

                # Try to detect a valid NTEE code column
                code_index = None
                for i, val in enumerate(results[0]):
                    if isinstance(val, str) and re.match(r"^[A-Z]\d{2}", val):  # like G41, E20, etc.
                        if val in code_to_desc:
                            code_index = i
                            break

                # Enrich results if possible
                if code_index is not None:
                    enriched_results = []
                    for row in results:
                        row = list(row)
                        code = row[code_index]
                        description = code_to_desc.get(code, "Unknown Sector")
                        row.append(description)
                        enriched_results.append(tuple(row))
                    results = enriched_results
            except Exception as e:
                # Optional: log or handle error
                pass

            # This line should not be indented under the try/except or if
            summary = summarize_findings_with_llm(user_query, schemas, results)
            return cleaned_query, results, summary

    return "No valid results found for any query.", None, None


st.title("CharityBot")
st.markdown("Ask about grants, foundations, or sectors. Get instant answers!")

# Conversation state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "awaiting_option" not in st.session_state:
    st.session_state.awaiting_option = False
if "top_similar" not in st.session_state:
    st.session_state.top_similar = None
if "user_query" not in st.session_state:
    st.session_state.user_query = None

def get_top_similar_queries(user_query):

    df = pd.read_csv(samplequery_path)
    queries = df['Question'].tolist()
    model_retrieval = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model_retrieval.encode(queries)
    embeddings = np.array(embeddings).astype('float32')
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    user_embedding = model_retrieval.encode([user_query])
    distances, indices = index.search(user_embedding, 3)
    top_similar = [(queries[idx], 1 / (1 + dist), idx) for dist, idx in zip(distances[0], indices[0])]
    return top_similar, df

# --- Chat Interface ---
def show_message(message, is_user):
    align = "user" if is_user else "assistant"
    st.chat_message(align).markdown(message)

for msg, is_user in st.session_state.messages:
    show_message(msg, is_user)
user_query = None
if not st.session_state.awaiting_option:
    user_query = st.chat_input("Type your question about grants or organizations...", key="main_input")
    if user_query:
        st.session_state.messages.append((user_query, True))
        show_message(user_query, is_user=True)
        # Get similar queries
        top_similar, df = get_top_similar_queries(user_query)
        st.session_state.top_similar = (top_similar, df)
        st.session_state.user_query = user_query
        st.session_state.awaiting_option = True
        st.rerun()
else:
    # Present options for selection
    top_similar, df = st.session_state.top_similar
    options = [q for q, sim, idx in top_similar]
    options.append("None of the above")
    st.markdown("**Did you mean one of these?**")
    selection = st.radio(
        label="Choose a query option:",
        options=options,
        index=len(options)-1,
        key=f"simq_{st.session_state.user_query}",
        label_visibility="collapsed"
    )
    submit = st.button("Submit", key=f"submit_option_{st.session_state.user_query}")
    if submit:
        user_query = st.session_state.user_query
        if selection != "None of the above":
            selected_idx = next(idx for (q, sim, idx) in top_similar if q == selection)
            selected_sql_query = df.iloc[selected_idx]['SQL Query']
            schemas = fetch_schema_from_db(db_path)
            cleaned_sql = clean_sql_query(selected_sql_query)
            results = execute_sql_query(db_path, cleaned_sql)
            summary = summarize_findings_with_llm(user_query, schemas, results)
        else:
            sql_query, results, summary = run_pipeline(user_query, db_path)
        st.session_state.messages.append((summary, False))
        show_message(summary, is_user=False)
        # Reset for next question
        st.session_state.awaiting_option = False
        st.session_state.top_similar = None
        st.session_state.user_query = None
        st.rerun()
